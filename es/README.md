# 📚 Papers Fundamentales de la IA Moderna

Una colección curada de los papers más influyentes que han definido el panorama de la Inteligencia Artificial moderna. Ideal para tener una referencia rápida de los pilares teóricos del Deep Learning.

---

## 🤖 Arquitecturas Transformer y Modelos de Lenguaje (LLMs)

### Attention Is All You Need
- **Autores:** Ashish Vaswani, et al.
- **Año:** 2017
- **Publicación:** [arXiv:1706.03762](https://arxiv.org/pdf/1706.03762)
- **Resumen Rápido:** Introduce la arquitectura **Transformer**, basada únicamente en mecanismos de atención. Eliminó la necesidad de recurrencia (RNNs) y permitió una paralelización masiva, sentando las bases para la mayoría de los modelos de lenguaje modernos como GPT y BERT.

---

### Language Models are Few-Shot Learners (GPT-3)
- **Autores:** Tom B. Brown, et al.
- **Año:** 2020
- **Publicación:** [arXiv:2005.14165](https://arxiv.org/pdf/2005.14165)
- **Resumen Rápido:** Llevó los LLMs a una escala sin precedentes (175 mil millones de parámetros). Introdujo el concepto de "in-context learning" o aprendizaje *few-shot*, donde el modelo puede aprender a realizar una tarea con solo ver unos pocos ejemplos en el prompt.
