#  Papers Fundamentales de la IA Moderna

Una colecci贸n curada de los papers m谩s influyentes que han definido el panorama de la Inteligencia Artificial moderna. Ideal para tener una referencia r谩pida de los pilares te贸ricos del Deep Learning.

---

##  Arquitecturas Transformer y Modelos de Lenguaje (LLMs)

### Attention Is All You Need
- **Autores:** Ashish Vaswani, et al.
- **A帽o:** 2017
- **Publicaci贸n:** [arXiv:1706.03762](https://arxiv.org/pdf/1706.03762)
- **Resumen R谩pido:** Introduce la arquitectura **Transformer**, basada 煤nicamente en mecanismos de atenci贸n. Elimin贸 la necesidad de recurrencia (RNNs) y permiti贸 una paralelizaci贸n masiva, sentando las bases para la mayor铆a de los modelos de lenguaje modernos como GPT y BERT.

---

### Language Models are Few-Shot Learners (GPT-3)
- **Autores:** Tom B. Brown, et al.
- **A帽o:** 2020
- **Publicaci贸n:** [arXiv:2005.14165](https://arxiv.org/pdf/2005.14165)
- **Resumen R谩pido:** Llev贸 los LLMs a una escala sin precedentes (175 mil millones de par谩metros). Introdujo el concepto de "in-context learning" o aprendizaje *few-shot*, donde el modelo puede aprender a realizar una tarea con solo ver unos pocos ejemplos en el prompt.
