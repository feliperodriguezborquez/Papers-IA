---
layout: default
---
# 游닄 Papers Fundamentales de la IA Moderna

Una colecci칩n curada de los papers m치s influyentes que han definido el panorama de la Inteligencia Artificial moderna. Ideal para tener una referencia r치pida de los pilares te칩ricos del Deep Learning.

---

<div class="papers-list">

  <section class="paper-category">
    <h2>游뱄 Arquitecturas Transformer y Modelos de Lenguaje (LLMs)</h2>

    <div class="paper-item" data-category="LLMs, Transformers">
      <h3>Attention Is All You Need</h3>
      <p class="paper-meta">
        <strong>Autores:</strong> Ashish Vaswani, et al.<br>
        <strong>A침o:</strong> 2017<br>
        <strong>Publicaci칩n:</strong> <a href="https://arxiv.org/pdf/1706.03762">arXiv:1706.03762</a>
      </p>
      <p class="paper-summary">Introdujo la arquitectura **Transformer** (encoder-decoder), ocupando como 칰nica base el mecanismo de atenci칩n, prescindiendo as칤 de las antiguas RNNs. Adem치s, realiz칩 toda la ingenier칤a necesaria para que el modelo sea funcional. Sent칩 las bases para los modernos LLMs.</p>
    </div>

    <div class="paper-item" data-category="LLMs, Few-Shot Learning">
      <h3>Language Models are Few-Shot Learners (GPT-3)</h3>
      <p class="paper-meta">
        <strong>Autores:</strong> Tom B. Brown, et al.<br>
        <strong>A침o:</strong> 2020<br>
        <strong>Publicaci칩n:</strong> <a href="https://arxiv.org/pdf/2005.14165">arXiv:2005.14165</a>
      </p>
      <p class="paper-summary">Llev칩 los LLMs a una escala sin precedentes (175 mil millones de par치metros). Introdujo el concepto de "in-context learning" o aprendizaje *few-shot*, donde el modelo puede aprender a realizar una tarea con solo ver unos pocos ejemplos en el prompt.</p>
    </div>

  </section>

</div>

### Language Models are Few-Shot Learners (GPT-3)
- **Autores:** Tom B. Brown, et al.
- **A침o:** 2020
- **Publicaci칩n:** [arXiv:2005.14165](https://arxiv.org/pdf/2005.14165)
- **Resumen R치pido:** Llev칩 los LLMs a una escala sin precedentes (175 mil millones de par치metros). Introdujo el concepto de "in-context learning" o aprendizaje *few-shot*, donde el modelo puede aprender a realizar una tarea con solo ver unos pocos ejemplos en el prompt.
